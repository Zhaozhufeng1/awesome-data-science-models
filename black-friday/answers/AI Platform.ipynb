{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define environment variables</b>\n",
    "\n",
    "To be used in future training steps.  Note that the BUCKET_NAME defined below must exist in the GCP project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BUCKET_NAME=ml-workshop-black-friday\n",
      "env: JOB_NAME=black_friday_trial_1\n",
      "env: TRAINING_PACKAGE_PATH=./trainer/\n",
      "env: MAIN_TRAINER_MODULE=trainer.rf_trainer\n",
      "env: REGION=us-central1\n",
      "env: RUNTIME_VERSION=1.14\n",
      "env: PYTHON_VERSION=3.5\n",
      "env: SCALE_TIER=CUSTOM\n",
      "env: MODEL_NAME=black_friday_mod_trial_1\n",
      "env: PROJECT_ID=mwe-sanofi-ml-workshop\n",
      "env: DATASET_ID=black_friday\n",
      "env: VERSION_NAME=v1\n",
      "env: FRAMEWORK=SCIKIT_LEARN\n"
     ]
    }
   ],
   "source": [
    "%env BUCKET_NAME=ml-workshop-black-friday\n",
    "%env JOB_NAME=black_friday_trial_1\n",
    "\n",
    "%env TRAINING_PACKAGE_PATH=./trainer/\n",
    "%env MAIN_TRAINER_MODULE=trainer.rf_trainer\n",
    "%env REGION=us-central1\n",
    "%env RUNTIME_VERSION=1.14\n",
    "%env PYTHON_VERSION=3.5\n",
    "%env SCALE_TIER=CUSTOM\n",
    "\n",
    "%env MODEL_NAME=black_friday_mod_trial_1\n",
    "%env PROJECT_ID=mwe-sanofi-ml-workshop\n",
    "%env DATASET_ID=black_friday\n",
    "%env VERSION_NAME=v1\n",
    "%env FRAMEWORK=SCIKIT_LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://ml-workshop-black-friday/...\n",
      "ServiceException: 409 Bucket ml-workshop-black-friday already exists.\n",
      "Copying file://train.csv [Content-Type=text/csv]...\n",
      "- [1 files][ 24.3 MiB/ 24.3 MiB]                                                \n",
      "Operation completed over 1 objects/24.3 MiB.                                     \n",
      "Copying file://test.csv [Content-Type=text/csv]...\n",
      "- [1 files][ 11.0 MiB/ 11.0 MiB]                                                \n",
      "Operation completed over 1 objects/11.0 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Training and testing files must be in a cloud storage bucket before training runs.\n",
    "!gsutil mb gs://${BUCKET_NAME}\n",
    "!gsutil cp train.csv  gs://${BUCKET_NAME}\n",
    "!gsutil cp test.csv  gs://${BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perform training locally with default parameters</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1it [00:15, 15.24s/it]\n",
      "Downloading: 100%|█████████████████| 627921/627921 [00:41<00:00, 15111.11rows/s]\n",
      "Downloading: 100%|█████████████████| 155746/155746 [00:10<00:00, 14316.64rows/s]\n",
      "Copying file://model.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  9.1 MiB/  9.1 MiB]                                                \n",
      "Operation completed over 1 objects/9.1 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Give the service account for this project an \"Editor\" role in IAM for all users of this environment\n",
    "# to have Bigquery access. This is needed if create-data=True is set below.\n",
    "# If the table already exists, set create-data=False.\n",
    "!gcloud ai-platform local train \\\n",
    "  --package-path $TRAINING_PACKAGE_PATH \\\n",
    "  --module-name $MAIN_TRAINER_MODULE \\\n",
    "  -- \\\n",
    "  --create-data=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perform training on AI Platform</b>\n",
    "\n",
    "The training job can also be run on AI Platform. \n",
    "\n",
    "Important: A single training job (either locally or using AI Platform) must complete with the --create-data  and --hp-tune flags set to True for the remainig functionality to complete.\n",
    "\n",
    "Note that we've updated the compute allocated to the master machine for this job to allow for more muscle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [black_friday_trial_1] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe black_friday_trial_1\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs black_friday_trial_1\n",
      "jobId: black_friday_trial_1\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --job-dir gs://${BUCKET_NAME}/rf-job-dir \\\n",
    "  --package-path $TRAINING_PACKAGE_PATH \\\n",
    "  --module-name $MAIN_TRAINER_MODULE \\\n",
    "  --region $REGION \\\n",
    "  --runtime-version=$RUNTIME_VERSION \\\n",
    "  --python-version=$PYTHON_VERSION \\\n",
    "  --scale-tier $SCALE_TIER \\\n",
    "  --master-machine-type n1-highcpu-16 \\\n",
    "  -- \\\n",
    "  --job-id $JOB_NAME \\\n",
    "  --project-id $PROJECT_ID \\\n",
    "  --bucket-name $BUCKET_NAME \\\n",
    "  --dataset-id $DATASET_ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream logs so that training is done before subsequent cells are run.\n",
    "# Remove  '> /dev/null' to see step-by-step output of the model build steps.\n",
    "!gcloud ai-platform jobs stream-logs $JOB_NAME > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2020-06-10T21:29:48Z'\n",
      "endTime: '2020-06-10T21:34:21Z'\n",
      "errorMessage: |-\n",
      "  The replica master 0 exited with a non-zero status of 1. \n",
      "  Traceback (most recent call last):\n",
      "    [...]\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/google/resumable_media/requests/download.py\", line 153, in consume\n",
      "      self._process_response(result)\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/google/resumable_media/_download.py\", line 171, in _process_response\n",
      "      response, _ACCEPTABLE_STATUS_CODES, self._get_status_code\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/google/resumable_media/_helpers.py\", line 96, in require_status_code\n",
      "      *status_codes\n",
      "  google.resumable_media.common.InvalidResponse: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)\n",
      "\n",
      "  During handling of the above exception, another exception occurred:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "      \"__main__\", mod_spec)\n",
      "    File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/root/.local/lib/python3.5/site-packages/trainer/rf_trainer.py\", line 155, in <module>\n",
      "      train_and_evaluate(args)\n",
      "    File \"/root/.local/lib/python3.5/site-packages/trainer/rf_trainer.py\", line 33, in train_and_evaluate\n",
      "      blob.download_to_filename(args.train_file_x)\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/google/cloud/storage/blob.py\", line 520, in download_to_filename\n",
      "      self.download_to_file(file_obj, client=client)\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/google/cloud/storage/blob.py\", line 500, in download_to_file\n",
      "      _raise_from_invalid_response(exc)\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/google/cloud/storage/blob.py\", line 1735, in _raise_from_invalid_response\n",
      "      raise exceptions.from_http_response(error.response)\n",
      "  google.api_core.exceptions.NotFound: 404 GET https://www.googleapis.com/download/storage/v1/b/ml-workshop-black-friday/o/x_train.csv?alt=media: No such object: ml-workshop-black-friday/x_train.csv\n",
      "\n",
      "  To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=932150155018&resource=ml_job%2Fjob_id%2Fblack_friday_trial_1&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%22black_friday_trial_1%22\n",
      "etag: KsoD1-1KR5w=\n",
      "jobId: black_friday_trial_1\n",
      "startTime: '2020-06-10T21:30:42Z'\n",
      "state: FAILED\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --job-id\n",
      "  - black_friday_trial_1\n",
      "  - --project-id\n",
      "  - mwe-sanofi-ml-workshop\n",
      "  - --bucket-name\n",
      "  - ml-workshop-black-friday\n",
      "  - --dataset-id\n",
      "  - black_friday\n",
      "  jobDir: gs://ml-workshop-black-friday/rf-job-dir\n",
      "  masterType: n1-highcpu-16\n",
      "  packageUris:\n",
      "  - gs://ml-workshop-black-friday/rf-job-dir/packages/a19601b07c3cdab0512c7190e182c4aed0616e11b946b07c9bcff28dfcca7441/trainer-0.1.tar.gz\n",
      "  pythonModule: trainer.rf_trainer\n",
      "  pythonVersion: '3.5'\n",
      "  region: us-central1\n",
      "  runtimeVersion: '1.14'\n",
      "  scaleTier: CUSTOM\n",
      "trainingOutput:\n",
      "  consumedMLUnits: 0.19\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/black_friday_trial_1?project=mwe-sanofi-ml-workshop\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fblack_friday_trial_1&project=mwe-sanofi-ml-workshop\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe black_friday_trial_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Host the trained model on AI Platform</b>\n",
    "\n",
    "Because our raw prediction output from the model is a numpy array that needs to be converted into a product category, we'll need to implement a custom prediction module.\n",
    "\n",
    "First, execute the setup script to create a distribution tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "creating trainer.egg-info\n",
      "writing trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to trainer.egg-info/dependency_links.txt\n",
      "writing requirements to trainer.egg-info/requires.txt\n",
      "writing top-level names to trainer.egg-info/top_level.txt\n",
      "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating trainer-0.1\n",
      "creating trainer-0.1/trainer\n",
      "creating trainer-0.1/trainer.egg-info\n",
      "copying files to trainer-0.1...\n",
      "copying predictor.py -> trainer-0.1\n",
      "copying setup.py -> trainer-0.1\n",
      "copying trainer/__init__.py -> trainer-0.1/trainer\n",
      "copying trainer/create_data_func.py -> trainer-0.1/trainer\n",
      "copying trainer/hp_tuning.py -> trainer-0.1/trainer\n",
      "copying trainer/rf_trainer.py -> trainer-0.1/trainer\n",
      "copying trainer.egg-info/PKG-INFO -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/SOURCES.txt -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/dependency_links.txt -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/requires.txt -> trainer-0.1/trainer.egg-info\n",
      "copying trainer.egg-info/top_level.txt -> trainer-0.1/trainer.egg-info\n",
      "Writing trainer-0.1/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'trainer-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!python setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next copy the tarball over to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://dist/trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  5.2 KiB/  5.2 KiB]                                                \n",
      "Operation completed over 1 objects/5.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp dist/trainer-0.1.tar.gz gs://${BUCKET_NAME}/staging-dir/trainer-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new model on AI Platform.  Note that this needs to be done just once, and future iterations are saved as \"versions\" of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Using endpoint [https://ml.googleapis.com/]\n",
      "Created ml engine model [projects/mwe-sanofi-ml-workshop/models/black_friday_mod_trial_1].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create $MODEL_NAME --regions $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create new version using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Using endpoint [https://ml.googleapis.com/]\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.ai-platform.versions.create) FAILED_PRECONDITION: Field: version.deployment_uri Error: The provided URI for model files doesn't contain any objects.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: The provided URI for model files doesn't contain any objects.\n",
      "    field: version.deployment_uri\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai-platform versions create $VERSION_NAME \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin gs://${BUCKET_NAME}/black_friday_${JOB_NAME}/ \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --python-version=3.5 \\\n",
    "  --package-uris gs://${BUCKET_NAME}/staging-dir/trainer-0.1.tar.gz \\\n",
    "  --prediction-class predictor.MyPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare a sample for inference</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Make an inference on a new sample.</b>\n",
    "\n",
    "Pass the sample object to the model hosted in AI Platform to return a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Using endpoint [https://ml.googleapis.com/]\n",
      "{\n",
      "  \"predictions\": \"Product Category 1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# make an online prediction\n",
    "!gcloud ai-platform predict --model $MODEL_NAME --version \\\n",
    "  $VERSION_NAME --json-instances input.json"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
